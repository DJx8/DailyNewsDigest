{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### INSTALL REQUIRED LIBRARIES"],"metadata":{"id":"_c9a7zonYFwj"}},{"cell_type":"code","source":["!pip install pandas nltk scikit-learn keras tensorflow newspaper3k networkx\n","!pip install lxml_html_clean\n","!pip install newspaper3k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CkK6D3EAlep","executionInfo":{"status":"ok","timestamp":1751115496902,"user_tz":-330,"elapsed":33843,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}},"outputId":"237df4e7-75d7-4377-dceb-9910434d7a81"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Collecting newspaper3k\n","  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.14.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.4)\n","Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.2.1)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n","Collecting cssselect>=0.9.2 (from newspaper3k)\n","  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.4.0)\n","Collecting feedparser>=5.2.1 (from newspaper3k)\n","  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n","Collecting tldextract>=2.0.1 (from newspaper3k)\n","  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n","Collecting feedfinder2>=0.0.4 (from newspaper3k)\n","  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jieba3k>=0.35.1 (from newspaper3k)\n","  Downloading jieba3k-0.35.1.zip (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tinysegmenter==0.3 (from newspaper3k)\n","  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n","Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n","  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.18.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n","Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n","Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n","  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=81fd2e85be84365a295e090ec25ea122cf3ee3b6190f337aed05404e6f00a4d1\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/f8/cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n","  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=a73868534f7133254510bf6b39aaae6e8a3848140a6062e2c6e34ae855e53fa0\n","  Stored in directory: /root/.cache/pip/wheels/80/d5/72/9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n","  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=98f796f6f1d4c4e93e91d0a638bcf2e9d449ab9dc2a0c75168ea92dd3cfa244b\n","  Stored in directory: /root/.cache/pip/wheels/3a/a1/46/8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=a41a628ebb623491246478cfb4bc1233ce11d03f38699848d3367f2f88505d3e\n","  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n","Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n","Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n","Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n","Collecting lxml_html_clean\n","  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from lxml_html_clean) (5.4.0)\n","Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n","Installing collected packages: lxml_html_clean\n","Successfully installed lxml_html_clean-0.4.2\n","Requirement already satisfied: newspaper3k in /usr/local/lib/python3.11/dist-packages (0.2.8)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.4)\n","Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.2.1)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n","Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (1.3.0)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.4.0)\n","Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n","Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.11)\n","Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.3.0)\n","Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.0.4)\n","Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.35.1)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.9.0.post0)\n","Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.14.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.6.15)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.18.0)\n"]}]},{"cell_type":"markdown","source":["### IMPORTS"],"metadata":{"id":"5dJM3iKhYMWV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import networkx as nx\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.stem import PorterStemmer\n","\n","from keras.utils import to_categorical\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, load_model\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from newspaper import Article\n","from sklearn.metrics.pairwise import cosine_similarity\n","nltk.download('punkt_tab')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0H_o9E2l_r5O","executionInfo":{"status":"ok","timestamp":1751115509712,"user_tz":-330,"elapsed":12807,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}},"outputId":"cb28733d-0e24-4780-ee9f-812087849b84"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","source":["### TEXT CLEANING"],"metadata":{"id":"2uKSMVrYYTWc"}},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()\n","\n","def clean_text(text):\n","    text = str(text).lower()\n","    tokens = word_tokenize(text)\n","    tokens = [t for t in tokens if t.isalpha()]\n","    tokens = [t for t in tokens if t not in stop_words]\n","    tokens = [stemmer.stem(t) for t in tokens]\n","    return ' '.join(tokens)"],"metadata":{"id":"W2CjTHq2_uQr","executionInfo":{"status":"ok","timestamp":1751115509715,"user_tz":-330,"elapsed":6,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### IMPORT DRIVE"],"metadata":{"id":"XxPajWrYYXdW"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"DoQoP727BZd0","executionInfo":{"status":"error","timestamp":1751115540164,"user_tz":-330,"elapsed":30445,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}},"outputId":"360246a9-dc8e-4097-c636-a7dc49f7cea7"},"execution_count":4,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"markdown","source":["### LOAD & PROCESS DATA"],"metadata":{"id":"or4M52LEYd5E"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/MyDrive/NLP/Project/Dataset/train.csv\")\n","df.columns = ['class_id', 'title', 'description']\n","\n","category_map = {\n","    1: 'World',\n","    2: 'Sports',\n","    3: 'Business',\n","    4: 'Sci/Tech'\n","}\n","df['category'] = df['class_id'].map(category_map)\n","df['text'] = df['title'].fillna('') + \". \" + df['description'].fillna('')\n","df['cleaned'] = df['text'].apply(clean_text)"],"metadata":{"id":"55C83ool_1up","executionInfo":{"status":"aborted","timestamp":1751115540214,"user_tz":-330,"elapsed":81,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TOKENIZATION"],"metadata":{"id":"G8gHb_o3aCbQ"}},{"cell_type":"code","source":["max_words = 5000\n","max_len = 200\n","\n","tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(df['cleaned'])\n","sequences = tokenizer.texts_to_sequences(df['cleaned'])\n","X = pad_sequences(sequences, maxlen=max_len)"],"metadata":{"id":"BTQ4EYH6_3N6","executionInfo":{"status":"aborted","timestamp":1751115540236,"user_tz":-330,"elapsed":98,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LABEL ENCODING"],"metadata":{"id":"C7mzg9QcaIMb"}},{"cell_type":"code","source":["le = LabelEncoder()\n","y = le.fit_transform(df['category'])\n","y = to_categorical(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"RH0omho__24k","executionInfo":{"status":"aborted","timestamp":1751115540238,"user_tz":-330,"elapsed":94,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LSTM MODEL"],"metadata":{"id":"0hvX-FqvaNSM"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n","model.add(LSTM(64, return_sequences=False))\n","model.add(Dropout(0.5))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(4, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n"],"metadata":{"id":"qFVoF8pJ__b_","executionInfo":{"status":"aborted","timestamp":1751115540240,"user_tz":-330,"elapsed":24,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TRAINING"],"metadata":{"id":"29mDJbvXaRmc"}},{"cell_type":"code","source":["model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"],"metadata":{"id":"svOyZK3UAFlp","executionInfo":{"status":"aborted","timestamp":1751115540242,"user_tz":-330,"elapsed":2,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### EVALUATION"],"metadata":{"id":"6j6rI_YoaW75"}},{"cell_type":"code","source":["loss, acc = model.evaluate(X_test, y_test)\n","print(f\"\\n✅ Test Accuracy: {acc:.2f}\")"],"metadata":{"id":"5SGDylpEAGs0","executionInfo":{"status":"aborted","timestamp":1751115540313,"user_tz":-330,"elapsed":70,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SUMMARIZATION FUNCTION"],"metadata":{"id":"pGuacHZgaawV"}},{"cell_type":"code","source":["def summarize(text, top_n=2, max_words=40):\n","    sentences = sent_tokenize(text)\n","    if len(sentences) <= top_n:\n","        return ' '.join(sentences[:top_n])\n","\n","    tfidf = Tokenizer()\n","    tfidf.fit_on_texts(sentences)\n","    tfidf_matrix = np.array([\n","        np.mean([tfidf.word_index.get(w, 0) for w in word_tokenize(s.lower()) if w.isalpha()], dtype=float)\n","        for s in sentences\n","    ]).reshape(-1, 1)\n","\n","    sim_matrix = cosine_similarity(tfidf_matrix)\n","    nx_graph = nx.from_numpy_array(sim_matrix)\n","    scores = nx.pagerank(nx_graph)\n","\n","    ranked = sorted(((scores[i], s, i) for i, s in enumerate(sentences)), reverse=True)\n","\n","    summary = []\n","    total_words = 0\n","    for _, sentence, idx in sorted(ranked[:len(sentences)], key=lambda x: x[2]):\n","        word_count = len(sentence.split())\n","        if total_words + word_count <= max_words:\n","            summary.append(sentence)\n","            total_words += word_count\n","        if len(summary) >= top_n or total_words >= max_words:\n","            break\n","\n","    return ' '.join(summary)\n"],"metadata":{"id":"G5Q1pfRBAIgp","executionInfo":{"status":"aborted","timestamp":1751115540315,"user_tz":-330,"elapsed":72,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### URL FETCH FUNCTION"],"metadata":{"id":"sXmk44fwafh6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5uxPXt0wquJQ","executionInfo":{"status":"aborted","timestamp":1751115540323,"user_tz":-330,"elapsed":80,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"outputs":[],"source":["def fetch_article(url):\n","    article = Article(url)\n","    article.download()\n","    article.parse()\n","    return article.title, article.text"]},{"cell_type":"markdown","source":["### PREDICT FUNCTION"],"metadata":{"id":"MlENTWnkajcK"}},{"cell_type":"code","source":["def infer_news_category_and_summary_dl(url):\n","    title, text = fetch_article(url)\n","    cleaned = clean_text(title + \". \" + text)\n","    seq = tokenizer.texts_to_sequences([cleaned])\n","    padded = pad_sequences(seq, maxlen=max_len)\n","\n","    prediction = model.predict(padded)\n","    category = le.inverse_transform([np.argmax(prediction)])[0]\n","    summary = summarize(text)\n","    return {\n","        \"title\": title,\n","        \"category\": category,\n","        \"summary\": summary\n","    }"],"metadata":{"id":"nS7cHik0rTov","executionInfo":{"status":"aborted","timestamp":1751115540325,"user_tz":-330,"elapsed":81,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### TEST URL"],"metadata":{"id":"CQU0AzaHanXw"}},{"cell_type":"code","source":["url = \"https://www.thehindu.com/sci-tech/technology/why-is-google-buying-out-its-employees-explained/article69743598.ece\"\n","result = infer_news_category_and_summary_dl(url)\n","\n","print(\"\\n📰 Title:\\n\", result['title'])\n","print(\"\\n📂 Predicted Category:\", result['category'])\n","print(\"\\n📝 Summary:\\n\", result['summary'])\n"],"metadata":{"id":"ZnfYCCaW_mJH","executionInfo":{"status":"aborted","timestamp":1751115540325,"user_tz":-330,"elapsed":39,"user":{"displayName":"DhananJay Vidyasagar","userId":"15279736691954369572"}}},"execution_count":null,"outputs":[]}]}